{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-26T21:55:24.552617Z","iopub.status.busy":"2023-12-26T21:55:24.552023Z","iopub.status.idle":"2023-12-26T21:55:24.924762Z","shell.execute_reply":"2023-12-26T21:55:24.923772Z","shell.execute_reply.started":"2023-12-26T21:55:24.552580Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/playground-series-s3e26/sample_submission.csv\n","/kaggle/input/playground-series-s3e26/train.csv\n","/kaggle/input/playground-series-s3e26/test.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-12-26T21:55:26.224719Z","iopub.status.busy":"2023-12-26T21:55:26.224157Z","iopub.status.idle":"2023-12-26T21:55:42.725830Z","shell.execute_reply":"2023-12-26T21:55:42.724506Z","shell.execute_reply.started":"2023-12-26T21:55:26.224685Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","198/198 [==============================] - 1s 4ms/step - loss: 0.6220 - accuracy: 0.7617 - val_loss: 0.5324 - val_accuracy: 0.7957\n","Epoch 2/20\n","198/198 [==============================] - 1s 3ms/step - loss: 0.5473 - accuracy: 0.7892 - val_loss: 0.5175 - val_accuracy: 0.8065\n","Epoch 3/20\n","198/198 [==============================] - 1s 4ms/step - loss: 0.5304 - accuracy: 0.7955 - val_loss: 0.5130 - val_accuracy: 0.8071\n","Epoch 4/20\n","198/198 [==============================] - 1s 3ms/step - loss: 0.5182 - accuracy: 0.8015 - val_loss: 0.5084 - val_accuracy: 0.8102\n","Epoch 5/20\n","198/198 [==============================] - 1s 3ms/step - loss: 0.5117 - accuracy: 0.8047 - val_loss: 0.5033 - val_accuracy: 0.8090\n","Epoch 6/20\n","198/198 [==============================] - 1s 3ms/step - loss: 0.5058 - accuracy: 0.8028 - val_loss: 0.5086 - val_accuracy: 0.8102\n","Epoch 7/20\n","198/198 [==============================] - 1s 3ms/step - loss: 0.5012 - accuracy: 0.8071 - val_loss: 0.5053 - val_accuracy: 0.8128\n","Epoch 8/20\n","198/198 [==============================] - 1s 3ms/step - loss: 0.5008 - accuracy: 0.8066 - val_loss: 0.5019 - val_accuracy: 0.8102\n","Epoch 9/20\n","198/198 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.8079 - val_loss: 0.4996 - val_accuracy: 0.8147\n","Epoch 10/20\n","198/198 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.8050 - val_loss: 0.5033 - val_accuracy: 0.8134\n","Epoch 11/20\n","198/198 [==============================] - 1s 3ms/step - loss: 0.4910 - accuracy: 0.8082 - val_loss: 0.4957 - val_accuracy: 0.8121\n","Epoch 12/20\n","198/198 [==============================] - 1s 3ms/step - loss: 0.4898 - accuracy: 0.8083 - val_loss: 0.4968 - val_accuracy: 0.8147\n","Epoch 13/20\n","198/198 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.8098 - val_loss: 0.4947 - val_accuracy: 0.8166\n","Epoch 14/20\n","198/198 [==============================] - 1s 3ms/step - loss: 0.4876 - accuracy: 0.8098 - val_loss: 0.4985 - val_accuracy: 0.8153\n","Epoch 15/20\n","198/198 [==============================] - 1s 3ms/step - loss: 0.4832 - accuracy: 0.8107 - val_loss: 0.4937 - val_accuracy: 0.8172\n","Epoch 16/20\n","198/198 [==============================] - 1s 3ms/step - loss: 0.4788 - accuracy: 0.8126 - val_loss: 0.4907 - val_accuracy: 0.8210\n","Epoch 17/20\n","198/198 [==============================] - 1s 3ms/step - loss: 0.4763 - accuracy: 0.8126 - val_loss: 0.4924 - val_accuracy: 0.8191\n","Epoch 18/20\n","198/198 [==============================] - 1s 3ms/step - loss: 0.4811 - accuracy: 0.8098 - val_loss: 0.4952 - val_accuracy: 0.8140\n","Epoch 19/20\n","198/198 [==============================] - 1s 3ms/step - loss: 0.4827 - accuracy: 0.8148 - val_loss: 0.4929 - val_accuracy: 0.8185\n","Epoch 20/20\n","198/198 [==============================] - 1s 3ms/step - loss: 0.4789 - accuracy: 0.8164 - val_loss: 0.4925 - val_accuracy: 0.8204\n","165/165 [==============================] - 0s 2ms/step\n"]}],"source":["import pandas as pd\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Define file paths\n","train_path = \"/kaggle/input/playground-series-s3e26/train.csv\"\n","test_path = \"/kaggle/input/playground-series-s3e26/test.csv\"\n","\n","# Load the training data\n","train_data = pd.read_csv(train_path)\n","\n","# Features and target variable\n","features = ['N_Days', 'Drug', 'Age', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema',\n","            'Bilirubin', 'Cholesterol', 'Albumin', 'Copper', 'Alk_Phos', 'SGOT', 'Tryglicerides',\n","            'Platelets', 'Prothrombin', 'Stage']\n","\n","target = 'Status'\n","\n","# Ensure categorical variables are encoded consistently\n","label_encoder = LabelEncoder()\n","\n","for col in features:\n","    if train_data[col].dtype == 'object':\n","        train_data[col] = label_encoder.fit_transform(train_data[col])\n","\n","# Encode the target variable\n","train_data['Status'] = label_encoder.fit_transform(train_data['Status'])\n","\n","# Split the data into features (X) and target variable (y)\n","X = train_data[features]\n","y = train_data['Status']\n","\n","# Convert y to one-hot encoding\n","y = tf.keras.utils.to_categorical(y)\n","\n","# Split the data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Normalize the features\n","X_mean = X_train.mean(axis=0)\n","X_std = X_train.std(axis=0)\n","X_train = (X_train - X_mean) / X_std\n","X_val = (X_val - X_mean) / X_std\n","\n","# Define the neural network model with adjusted hyperparameters\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n","    tf.keras.layers.Dropout(0.5),  # Introduce dropout regularization\n","    tf.keras.layers.Dense(3, activation='softmax')\n","])\n","\n","# Adjust the learning rate\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","\n","# Compile the model\n","model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val))\n","\n","# Load the test data\n","test_path = \"/kaggle/input/playground-series-s3e26/test.csv\"\n","test_data = pd.read_csv(test_path)\n","\n","# Encode categorical variables in the test set\n","for col in features:\n","    if test_data[col].dtype == 'object':\n","        test_data[col] = test_data[col].map(lambda s: '<unknown>' if s not in label_encoder.classes_ else s)\n","\n","# Convert non-numeric columns to numeric\n","test_data[features] = test_data[features].apply(pd.to_numeric, errors='coerce')\n","\n","# Handle missing values (NaN) in the test set\n","test_data[features] = test_data[features].fillna(0)  # You can replace 0 with any default value or use other imputation methods\n","\n","# Normalize the test features\n","X_test = (test_data[features] - X_mean) / X_std\n","\n","# Make predictions on the test set\n","predictions = model.predict(X_test)"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":7000181,"sourceId":60893,"sourceType":"competition"}],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
